---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


Iâ€™m a 1st-year Ph.D student at at [MMT lab](https://jiminxiao.github.io), University of Liverpool, advised by Prof. Jimin Xiao and Siyue Yu. Prior to that, I worked as a camera engineer for vivo Mobile Communication Ltd, focusing on Auto-Foucs & Image-Stablization.


I got my M.Eng. degree at [Institute of Information Science](http://mepro.bjtu.edu.cn) (Group Leader: Yao Zhao, IEEE Fellow), Beijing Jiaotong University, advised by Associate Prof. Meiqin Liu and Chao Yao.



My research interests cover a range of computer vision and deep learning, including image & video low-level vision, e.g. super-resolution, denosing, low-light enhancement, etc. and semantic segmentation under various supervisory conditions, including weakly supervised, zero-shot and continual learning environments. Currently, my research is primarily concentrated on open-vocabulary segmentation tasks and semantic-guided low-level vision.

<!--
neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).
-->

# ğŸ”¥ News
- *2023.08*: &nbsp;ğŸ‰ğŸ‰ Two papers accepted by ACM MM 2023. 
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ One paper accepted by T-CSVT.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2023</div><img src='images/KSNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Kernel Dimension Matters: To Activate Available Kernels for Real-time Video Super-Resolution](https://dl.acm.org/doi/pdf/10.1145/3581783.3611908)

**Shuo Jin**, Meiqin Liu, Chao Yao, Chunyu Lin, Yao Zhao
<!-- [**Project**](https://github.com/jxtse/GEC_Metrics_LLM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> | <a href="">Link to paper</a> -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2023</div><img src='images/CLG-INet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CLG-INet: Coupled Local-Global Interactive Network for Image Restoration](https://dl.acm.org/doi/pdf/10.1145/3581783.3612251)

Yuqi Jiang, Chune ZHANG, **Shuo Jin**, Jiao Liu, Jiapeng Wang
<!-- [**Project**](https://github.com/jxtse/GEC_Metrics_LLM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> | <a href="">Link to paper</a> -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE T-CSVT</div><img src='images/TCNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Temporal consistency learning of inter-frames for video super-resolution](https://ieeexplore.ieee.org/abstract/document/9919163)

Meiqin Liu, **Shuo Jin**, Chao Yao, Chunyu Lin, Yao Zhao
<!-- [**Project**](https://github.com/jxtse/GEC_Metrics_LLM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> | <a href="">Link to paper</a> -->
</div>
</div>

<!--
# ğŸ– Honors and Awards
- *2023.03* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2023.06* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
-->
# ğŸ“– Educations

- *2024.09 - 2028.12 (expected)*, Ph.D in Computer Science, University of Liverpool.
- *2021.09 - 2023.06*, M.Eng in Electronic Engineering, Beijing Jiaotong University.


<!--
# ğŸ’¬ Invited Talks
-->

# ğŸ’» Works & Internships
- *2023.07 - 2024.08 (full-time)*, vivo Mobile Communication Ltd.
